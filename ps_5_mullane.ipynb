{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy as sp\n",
    "import statsmodels.discrete.discrete_model as sm_model\n",
    "import statsmodels.tools as sm_tools\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 't', 'age', 'education', 'black', 'hispanic', 'married', 'nodegree', 're74', 're75', 're78', 'u74', 'u75'])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_path = \"nswre74_treated.mat\"\n",
    "mat_data = sp.io.loadmat(file1_path)\n",
    "mat_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treated</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>earn_74</th>\n",
       "      <th>earn_75</th>\n",
       "      <th>earn_78</th>\n",
       "      <th>u_74</th>\n",
       "      <th>u_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.930046</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.595894</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>24.909450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.506146</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.289790</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.27995</td>\n",
       "      <td>10.94135</td>\n",
       "      <td>15.952600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.04007</td>\n",
       "      <td>11.53657</td>\n",
       "      <td>36.646950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.60243</td>\n",
       "      <td>13.83064</td>\n",
       "      <td>12.803970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.73207</td>\n",
       "      <td>17.97615</td>\n",
       "      <td>3.786628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.66071</td>\n",
       "      <td>25.14224</td>\n",
       "      <td>4.181942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     treated  age  educ  black  hisp  married  nodegree   earn_74   earn_75  \\\n",
       "0          1   37    11      1     0        1         1   0.00000   0.00000   \n",
       "1          1   22     9      0     1        0         1   0.00000   0.00000   \n",
       "2          1   30    12      1     0        0         0   0.00000   0.00000   \n",
       "3          1   27    11      1     0        0         1   0.00000   0.00000   \n",
       "4          1   33     8      1     0        0         1   0.00000   0.00000   \n",
       "..       ...  ...   ...    ...   ...      ...       ...       ...       ...   \n",
       "180        1   33    12      1     0        1         0  20.27995  10.94135   \n",
       "181        1   25    14      1     0        1         0  35.04007  11.53657   \n",
       "182        1   35     9      1     0        1         1  13.60243  13.83064   \n",
       "183        1   35     8      1     0        1         1  13.73207  17.97615   \n",
       "184        1   33    11      1     0        1         1  14.66071  25.14224   \n",
       "\n",
       "       earn_78  u_74  u_75  \n",
       "0     9.930046     1     1  \n",
       "1     3.595894     1     1  \n",
       "2    24.909450     1     1  \n",
       "3     7.506146     1     1  \n",
       "4     0.289790     1     1  \n",
       "..         ...   ...   ...  \n",
       "180  15.952600     0     0  \n",
       "181  36.646950     0     0  \n",
       "182  12.803970     0     0  \n",
       "183   3.786628     0     0  \n",
       "184   4.181942     0     0  \n",
       "\n",
       "[185 rows x 12 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the variables\n",
    "treated = mat_data['t'].flatten()\n",
    "age = mat_data['age'].flatten()\n",
    "educ = mat_data['education'].flatten()\n",
    "black = mat_data['black'].flatten()\n",
    "hisp = mat_data['hispanic'].flatten()\n",
    "married = mat_data['married'].flatten()\n",
    "nodegree = mat_data['nodegree'].flatten()\n",
    "earn_74 = mat_data['re74'].flatten()\n",
    "earn_75 = mat_data['re75'].flatten()\n",
    "earn_78 = mat_data['re78'].flatten()\n",
    "u_74 = mat_data['u74'].flatten()\n",
    "u_75 = mat_data['u75'].flatten()\n",
    "\n",
    "# Create a DataFrame\n",
    "df_treat = pd.DataFrame({\n",
    "    'treated': treated,\n",
    "    'age': age,\n",
    "    'educ': educ,\n",
    "    'black': black,\n",
    "    'hisp': hisp,\n",
    "    'married': married,\n",
    "    'nodegree': nodegree,\n",
    "    'earn_74': earn_74/1000,\n",
    "    'earn_75': earn_75/1000,\n",
    "    'earn_78': earn_78/1000,\n",
    "    'u_74': u_74,\n",
    "    'u_75': u_75\n",
    "})\n",
    "df_treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 't', 'age', 'education', 'black', 'hispanic', 'married', 'nodegree', 're74', 're75', 're78', 'u74', 'u75'])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file3_path = \"cps_controls.mat\"\n",
    "mat_data = sp.io.loadmat(file3_path)\n",
    "mat_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3_path = \"cps_controls.mat\"\n",
    "mat_data = sp.io.loadmat(file3_path)\n",
    "mat_data.keys()\n",
    "\n",
    "# Extract the variables\n",
    "treated = mat_data['t'].flatten()\n",
    "age = mat_data['age'].flatten()\n",
    "educ = mat_data['education'].flatten()\n",
    "black = mat_data['black'].flatten()\n",
    "hisp = mat_data['hispanic'].flatten()\n",
    "married = mat_data['married'].flatten()\n",
    "nodegree = mat_data['nodegree'].flatten()\n",
    "earn_74 = mat_data['re74'].flatten()\n",
    "earn_75 = mat_data['re75'].flatten()\n",
    "earn_78 = mat_data['re78'].flatten()\n",
    "u_74 = mat_data['u74'].flatten()\n",
    "u_75 = mat_data['u75'].flatten()\n",
    "\n",
    "# Create a DataFrame\n",
    "df_control = pd.DataFrame({\n",
    "    'treated': treated,\n",
    "    'age': age,\n",
    "    'educ': educ,\n",
    "    'black': black,\n",
    "    'hisp': hisp,\n",
    "    'married': married,\n",
    "    'nodegree': nodegree,\n",
    "    'earn_74': earn_74/1000,\n",
    "    'earn_75': earn_75/1000,\n",
    "    'earn_78': earn_78/1000,\n",
    "    'u_74': u_74,\n",
    "    'u_75': u_75,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.a. Contruct table with normalized differences in covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "treat_covars = df_treat.iloc[:, 1:].drop(columns=['earn_78'])\n",
    "control_covars = df_control.iloc[:, 1:].drop(columns=['earn_78'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = treat_covars.mean()-control_covars.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmullane/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "s_0 = (np.sum((control_covars - control_covars.mean())**2))/(len(control_covars)-1)\n",
    "s_1 = (np.sum((treat_covars - treat_covars.mean())**2))/(len(treat_covars)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        -0.796183\n",
       "educ       -0.678502\n",
       "black       2.427747\n",
       "hisp       -0.050697\n",
       "married    -1.232648\n",
       "nodegree    0.903811\n",
       "earn_74    -1.568990\n",
       "earn_75    -1.746428\n",
       "u_74        1.487257\n",
       "u_75        1.192450\n",
       "dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_diff = df_diff/np.sqrt((s_0 + s_1)/2)\n",
    "norm_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Estimate propensity score (linear covars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_treat, df_control], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_list = ['age', 'educ', 'black', 'hisp', 'married', 'nodegree', 'earn_74', 'earn_75', 'u_74', 'u_75']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = df[covar_list]\n",
    "covars = sm_tools.add_constant(covars)\n",
    "treat = df['treated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029675\n",
      "         Iterations 11\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                treated   No. Observations:                16177\n",
      "Model:                         Probit   Df Residuals:                    16166\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Sun, 11 May 2025   Pseudo R-squ.:                  0.5252\n",
      "Time:                        22:47:48   Log-Likelihood:                -480.05\n",
      "converged:                       True   LL-Null:                       -1011.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.996e-222\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -2.9962      0.390     -7.681      0.000      -3.761      -2.232\n",
      "age           -0.0103      0.005     -1.934      0.053      -0.021       0.000\n",
      "educ           0.0055      0.024      0.229      0.819      -0.042       0.053\n",
      "black          1.9578      0.109     17.935      0.000       1.744       2.172\n",
      "hisp           0.7847      0.164      4.798      0.000       0.464       1.105\n",
      "married       -0.4584      0.114     -4.023      0.000      -0.682      -0.235\n",
      "nodegree       0.3944      0.134      2.939      0.003       0.131       0.657\n",
      "earn_74        0.0264      0.013      2.032      0.042       0.001       0.052\n",
      "earn_75       -0.0761      0.016     -4.909      0.000      -0.107      -0.046\n",
      "u_74           0.7810      0.130      6.001      0.000       0.526       1.036\n",
      "u_75           0.1246      0.118      1.055      0.291      -0.107       0.356\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.60 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "# Formula-based approach\n",
    "formula = \"treated ~ \" + \" + \".join(covar_list)\n",
    "probit_formula = smf.probit(formula, data=df)\n",
    "probit_results = probit_formula.fit()\n",
    "print(probit_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e(x) distribution: count    1.617700e+04\n",
      "mean     1.143629e-02\n",
      "std      5.532375e-02\n",
      "min      4.802004e-09\n",
      "25%      1.232289e-06\n",
      "50%      2.458182e-05\n",
      "75%      9.665958e-04\n",
      "max      5.605503e-01\n",
      "Name: propensity_score, dtype: float64\n",
      "e(x) distribution of control: count    1.599200e+04\n",
      "mean     8.116811e-03\n",
      "std      4.128089e-02\n",
      "min      4.802004e-09\n",
      "25%      1.200035e-06\n",
      "50%      2.274042e-05\n",
      "75%      8.237204e-04\n",
      "max      5.605503e-01\n",
      "Name: propensity_score, dtype: float64\n",
      "e(x) distribution of treated: count    185.000000\n",
      "mean       0.298383\n",
      "std        0.192959\n",
      "min        0.000147\n",
      "25%        0.128483\n",
      "50%        0.324726\n",
      "75%        0.503160\n",
      "max        0.556500\n",
      "Name: propensity_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate propensity scores\n",
    "df['propensity_score'] = probit_results.predict()\n",
    "# df['propensity_score'] = probit_results.predict(covars, linear=True)\n",
    "\n",
    "# Examine the distribution of propensity scores\n",
    "print(\"e(x) distribution:\", df['propensity_score'].describe())\n",
    "print(\"e(x) distribution of control:\", df[df['treated']==0]['propensity_score'].describe())\n",
    "print(\"e(x) distribution of treated:\",df[df['treated']==1]['propensity_score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Calculate weighted ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'] = np.where(\n",
    "    df['treated'] == 1,\n",
    "    1,\n",
    "    df['propensity_score'] / (1 - df['propensity_score'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.599200e+04\n",
      "mean     1.000000e+00\n",
      "std      6.582768e+00\n",
      "min      4.307648e-07\n",
      "25%      1.076495e-04\n",
      "50%      2.039980e-03\n",
      "75%      7.395292e-02\n",
      "max      1.144256e+02\n",
      "Name: weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Taegan's version\n",
    "weights_control = df['weight'][df['treated'] == 0]\n",
    "weights_control_norm = weights_control * len(weights_control)/sum(weights_control)\n",
    "print(weights_control_norm.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14156    114.425557\n",
       "9569     114.425557\n",
       "11452    114.425557\n",
       "15757    113.556873\n",
       "2761     113.421985\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_weights = weights_control_norm.sort_values(ascending=False).head(5)\n",
    "top_5_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>earn_74</th>\n",
       "      <th>earn_75</th>\n",
       "      <th>u_74</th>\n",
       "      <th>u_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14156</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9569</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15757</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  age  educ  black  hisp  married  nodegree  earn_74  earn_75  \\\n",
       "14156    1.0   16    10      1     0        0         1      0.0      0.0   \n",
       "9569     1.0   16    10      1     0        0         1      0.0      0.0   \n",
       "11452    1.0   16    10      1     0        0         1      0.0      0.0   \n",
       "15757    1.0   17    11      1     0        0         1      0.0      0.0   \n",
       "2761     1.0   16     9      1     0        0         1      0.0      0.0   \n",
       "\n",
       "       u_74  u_75  \n",
       "14156     1     1  \n",
       "9569      1     1  \n",
       "11452     1     1  \n",
       "15757     1     1  \n",
       "2761      1     1  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.loc[top_5_weights.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att(df):\n",
    "    treated = df['treated'] == 1\n",
    "    control = df['treated'] == 0\n",
    "        \n",
    "    weights_control = df['propensity_score'][control] / (1 - df['propensity_score'][control])\n",
    "    weights_control_norm = weights_control * len(weights_control) / sum(weights_control)\n",
    "        \n",
    "    att = np.mean(df['earn_78'][treated]) - (df['earn_78'][control]*weights_control).sum()/treated.sum()\n",
    "    return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.4008460929182087)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_estimate = att(df)\n",
    "att_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE= 0.8179463036989164\n"
     ]
    }
   ],
   "source": [
    "att_boots = []\n",
    "for _ in range(1000):\n",
    "    boot_sample = resample(df)\n",
    "    att_boot = att(boot_sample)\n",
    "    att_boots.append(att_boot)\n",
    "\n",
    "att_std_error = np.std(att_boots)\n",
    "print(\"SE=\", att_std_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Repeat with logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029377\n",
      "         Iterations 12\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                treated   No. Observations:                16177\n",
      "Model:                          Logit   Df Residuals:                    16166\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Sun, 11 May 2025   Pseudo R-squ.:                  0.5300\n",
      "Time:                        22:30:13   Log-Likelihood:                -475.23\n",
      "converged:                       True   LL-Null:                       -1011.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.679e-224\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -6.3408      0.812     -7.804      0.000      -7.933      -4.748\n",
      "age           -0.0179      0.011     -1.683      0.092      -0.039       0.003\n",
      "educ           0.0195      0.049      0.401      0.688      -0.076       0.115\n",
      "black          4.2858      0.263     16.319      0.000       3.771       4.801\n",
      "hisp           1.8356      0.394      4.663      0.000       1.064       2.607\n",
      "married       -0.9943      0.241     -4.120      0.000      -1.467      -0.521\n",
      "nodegree       0.9028      0.275      3.282      0.001       0.364       1.442\n",
      "earn_74        0.0625      0.028      2.197      0.028       0.007       0.118\n",
      "earn_75       -0.1773      0.036     -4.923      0.000      -0.248      -0.107\n",
      "u_74           1.5720      0.264      5.956      0.000       1.055       2.089\n",
      "u_75           0.2347      0.239      0.984      0.325      -0.233       0.702\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.39 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "# Formula-based approach\n",
    "formula = \"treated ~ \" + \" + \".join(covar_list)\n",
    "logit_formula = smf.logit(formula, data=df)\n",
    "logit_results = logit_formula.fit()\n",
    "print(logit_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit = sm_model.Logit(treat, covars)\n",
    "# logit_results = logit.fit(maxiter=10000)\n",
    "# print(\"logit:\",logit_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    16177.000000\n",
      "mean         0.011436\n",
      "std          0.059658\n",
      "min          0.000005\n",
      "25%          0.000048\n",
      "50%          0.000208\n",
      "75%          0.001744\n",
      "max          0.637511\n",
      "Name: propensity_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate propensity scores\n",
    "# df['propensity_score'] = logit_results.predict(covars, linear=True)\n",
    "df['propensity_score'] = logit_results.predict()\n",
    "\n",
    "# Examine the distribution of propensity scores\n",
    "print(df['propensity_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight_log'] = np.where(\n",
    "    df['treated'] == 1,\n",
    "    1,\n",
    "    df['propensity_score'] / (1 - df['propensity_score'])    # equation when flag == 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    15992.000000\n",
      "mean         1.000000\n",
      "std          7.806084\n",
      "min          0.000400\n",
      "25%          0.004056\n",
      "50%          0.016981\n",
      "75%          0.134161\n",
      "max        149.498966\n",
      "Name: weight_log, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "weights_control_log = df['weight_log'][df['treated'] == 0]\n",
    "weights_control_norm_log = weights_control_log * len(weights_control_log)/sum(weights_control_log)\n",
    "print(weights_control_norm_log.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15757    149.498966\n",
       "11452    149.262577\n",
       "14156    149.262577\n",
       "9569     149.262577\n",
       "2781     146.846240\n",
       "Name: weight_log, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_weights_log = weights_control_norm_log.sort_values(ascending=False).head(5)\n",
    "top_5_weights_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>earn_74</th>\n",
       "      <th>earn_75</th>\n",
       "      <th>u_74</th>\n",
       "      <th>u_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15757</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14156</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9569</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  age  educ  black  hisp  married  nodegree  earn_74  earn_75  \\\n",
       "15757    1.0   17    11      1     0        0         1      0.0      0.0   \n",
       "11452    1.0   16    10      1     0        0         1      0.0      0.0   \n",
       "14156    1.0   16    10      1     0        0         1      0.0      0.0   \n",
       "9569     1.0   16    10      1     0        0         1      0.0      0.0   \n",
       "2781     1.0   18    11      1     0        0         1      0.0      0.0   \n",
       "\n",
       "       u_74  u_75  \n",
       "15757     1     1  \n",
       "11452     1     1  \n",
       "14156     1     1  \n",
       "9569      1     1  \n",
       "2781      1     1  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.loc[top_5_weights_log.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.2930040476864395)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_estimate_logit = att(df)\n",
    "att_estimate_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE= 0.786942543960108\n"
     ]
    }
   ],
   "source": [
    "att_logit_boots = []\n",
    "for _ in range(1000):\n",
    "    boot_sample = resample(df)\n",
    "    att_boot = att(boot_sample)\n",
    "    att_logit_boots.append(att_boot)\n",
    "\n",
    "att_logit_std_error = np.std(att_logit_boots)\n",
    "print(\"SE=\", att_logit_std_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Construct strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stratum\n",
       "1    15640\n",
       "2      228\n",
       "3       57\n",
       "4       41\n",
       "5       26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated_ps = df[df['treated'] == 1]['propensity_score']\n",
    "quintiles = np.percentile(treated_ps, [20, 40, 60, 80])\n",
    "df['stratum'] = pd.cut(df['propensity_score'], \n",
    "                       bins=[-np.inf] + list(quintiles) + [np.inf], \n",
    "                       labels=[1, 2, 3, 4, 5])\n",
    "control_counts = df[df['treated'] == 0]['stratum'].value_counts().sort_index()\n",
    "control_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Normalized differences in each stratum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'educ', 'black', 'hisp', 'married', 'nodegree', 'earn_74',\n",
       "       'earn_75', 'u_74', 'u_75'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_0.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(121.99679157632723)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_0['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmullane/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/Users/tmullane/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/Users/tmullane/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/Users/tmullane/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/Users/tmullane/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'age': np.float64(-0.8349576068166848),\n",
       "  'educ': np.float64(-0.49749777871901985),\n",
       "  'black': np.float64(0.7227325873537844),\n",
       "  'hisp': np.float64(0.35285671315376954),\n",
       "  'married': np.float64(-0.6707483642248573),\n",
       "  'nodegree': np.float64(0.5248097322768831),\n",
       "  'earn_74': np.float64(-1.1003250192884422),\n",
       "  'earn_75': np.float64(-1.2610067155153504),\n",
       "  'u_74': np.float64(0.7719165315845047),\n",
       "  'u_75': np.float64(0.5046337189295692),\n",
       "  'propensity_score_log': np.float64(1.0978859389212667)},\n",
       " 2: {'age': np.float64(-0.06071993986732214),\n",
       "  'educ': np.float64(-0.29511108822457477),\n",
       "  'black': np.float64(0.18113349331692472),\n",
       "  'hisp': np.float64(-0.1811334933169248),\n",
       "  'married': np.float64(-0.2169114450737581),\n",
       "  'nodegree': np.float64(0.3387941813610128),\n",
       "  'earn_74': np.float64(0.24556951625016615),\n",
       "  'earn_75': np.float64(0.4130350497864614),\n",
       "  'u_74': np.float64(-0.33615135864580875),\n",
       "  'u_75': np.float64(-0.49820650586251625),\n",
       "  'propensity_score_log': np.float64(-0.012880397162272433)},\n",
       " 3: {'age': np.float64(-0.46155222426246095),\n",
       "  'educ': np.float64(0.307899343379012),\n",
       "  'black': 0,\n",
       "  'hisp': 0,\n",
       "  'married': np.float64(0.09312591423125363),\n",
       "  'nodegree': np.float64(-0.11187422380307539),\n",
       "  'earn_74': np.float64(-0.060436939304781896),\n",
       "  'earn_75': np.float64(0.1398441666177167),\n",
       "  'u_74': np.float64(0.3607546894483361),\n",
       "  'u_75': np.float64(-0.05574260814585663),\n",
       "  'propensity_score_log': np.float64(0.7914340321367966)},\n",
       " 4: {'age': np.float64(0.35966884839259194),\n",
       "  'educ': np.float64(-0.02288669178467052),\n",
       "  'black': 0,\n",
       "  'hisp': 0,\n",
       "  'married': 0,\n",
       "  'nodegree': np.float64(-0.11500481782948203),\n",
       "  'earn_74': 0,\n",
       "  'earn_75': np.float64(-0.3226372711821615),\n",
       "  'u_74': 0,\n",
       "  'u_75': np.float64(0.802731925929673),\n",
       "  'propensity_score_log': np.float64(0.10982240059270108)},\n",
       " 5: {'age': np.float64(1.0104889609412762),\n",
       "  'educ': np.float64(0.09354965811441955),\n",
       "  'black': 0,\n",
       "  'hisp': 0,\n",
       "  'married': 0,\n",
       "  'nodegree': 0,\n",
       "  'earn_74': 0,\n",
       "  'earn_75': 0,\n",
       "  'u_74': 0,\n",
       "  'u_75': 0,\n",
       "  'propensity_score_log': np.float64(-1.1277589996985116)}}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dist = {}\n",
    "for stratum in range(1, 6):\n",
    "    strat_cov = {}\n",
    "    stratum_data = df[df['stratum'] == stratum].drop(columns=['earn_78','propensity_score', 'stratum','weight', 'weight_log'])\n",
    "    treat_covars = stratum_data[stratum_data['treated'] == 1].iloc[:, 1:]\n",
    "    control_covars = stratum_data[stratum_data['treated'] == 0].iloc[:, 1:]\n",
    "    df_diff = treat_covars.mean()-control_covars.mean()\n",
    "    s_0 = (np.sum((control_covars - control_covars.mean())**2))/(len(control_covars)-1)\n",
    "    s_1 = (np.sum((treat_covars - treat_covars.mean())**2))/(len(treat_covars)-1)\n",
    "\n",
    "    for cov in s_0.index.values:\n",
    "        if s_0[cov] == 0 and s_1[cov] == 0:\n",
    "            strat_cov[cov] = 0\n",
    "        elif s_0[cov] == 0 or s_1[cov] == 0:\n",
    "            strat_cov[cov] = np.inf if df_diff[cov]!= 0 else 0\n",
    "        else:\n",
    "            strat_cov[cov] = df_diff[cov]/np.sqrt((s_0[cov] + s_1[cov])/2)\n",
    "\n",
    "        norm_dist[stratum] = strat_cov\n",
    "\n",
    "norm_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratum_sizes = df[df['treated'] == 1]['stratum'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 0.0025856076774800458\n",
      "educ -0.08280931144696672\n",
      "black 0.18077321613414182\n",
      "hisp 0.03434464396736895\n",
      "married -0.15890677901347236\n",
      "nodegree 0.12734497440106768\n",
      "earn_74 -0.18303848846861157\n",
      "earn_75 -0.2061529540586667\n",
      "u_74 0.1593039724774064\n",
      "u_75 0.1506833061701739\n"
     ]
    }
   ],
   "source": [
    "weighted_diffs = {}\n",
    "for cov in covars.columns[1:]:\n",
    "    weighted_diff = sum(norm_dist[s][cov] * stratum_sizes[s] for s in range(1, 6)) / sum(stratum_sizes)\n",
    "    weighted_diffs[cov] = weighted_diff\n",
    "\n",
    "for cov, diff in weighted_diffs.items():\n",
    "    print(cov, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced covariates:\n",
      "black: 0.1808\n",
      "married: -0.1589\n",
      "nodegree: 0.1273\n",
      "earn_74: -0.1830\n",
      "earn_75: -0.2062\n",
      "u_74: 0.1593\n",
      "u_75: 0.1507\n",
      "\n",
      "Most imbalanced stratum: 1 (max normalized difference: 1.2610)\n"
     ]
    }
   ],
   "source": [
    "# Identify unbalanced covariates (e.g., |diff| > 0.1)\n",
    "unbalanced = {cov: diff for cov, diff in weighted_diffs.items() if abs(diff) > 0.1}\n",
    "if unbalanced:\n",
    "    print(\"\\nUnbalanced covariates:\")\n",
    "    for cov, diff in unbalanced.items():\n",
    "        print(f\"{cov}: {diff:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo covariates are very unbalanced.\")\n",
    "\n",
    "# Identify most imbalanced stratum\n",
    "stratum_imbalance = {}\n",
    "for stratum in range(1, 6):\n",
    "    stratum_imbalance[stratum] = max(abs(diff) for diff in norm_dist[stratum].values())\n",
    "\n",
    "most_imbalanced = max(stratum_imbalance, key=stratum_imbalance.get)\n",
    "print(f\"\\nMost imbalanced stratum: {most_imbalanced} (max normalized difference: {stratum_imbalance[most_imbalanced]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Avg effect within each strata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'effect': np.float64(-0.5473752309469494),\n",
       "  'se': np.float64(1.1584031156630086),\n",
       "  'p_value': np.float64(0.6365581924021968),\n",
       "  'n_treated': 37,\n",
       "  'n_control': 26,\n",
       "  'model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x320305ca0>},\n",
       " 2: {'effect': np.float64(-0.5616618207808856),\n",
       "  'se': np.float64(1.1020698805314393),\n",
       "  'p_value': np.float64(0.6107443439556998),\n",
       "  'n_treated': 37,\n",
       "  'n_control': 26,\n",
       "  'model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1755ee700>},\n",
       " 3: {'effect': np.float64(5.148354818875081),\n",
       "  'se': np.float64(1.4987489302534502),\n",
       "  'p_value': np.float64(0.0009227051752241825),\n",
       "  'n_treated': 37,\n",
       "  'n_control': 26,\n",
       "  'model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1603dad60>},\n",
       " 4: {'effect': np.float64(5.127531521080948),\n",
       "  'se': np.float64(2.1316285572119313),\n",
       "  'p_value': np.float64(0.018760286790387277),\n",
       "  'n_treated': 37,\n",
       "  'n_control': 26,\n",
       "  'model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1603e7dc0>},\n",
       " 5: {'effect': np.float64(0.055687423357948074),\n",
       "  'se': np.float64(1.3598780954386487),\n",
       "  'p_value': np.float64(0.9674737765075332),\n",
       "  'n_treated': 37,\n",
       "  'n_control': 26,\n",
       "  'model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1603ec6a0>}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lin_model(df):\n",
    "    covars = df.drop(columns=['earn_78'])\n",
    "    covars = sm_tools.add_constant(covars)\n",
    "    out = df['earn_78']\n",
    "    lin_reg = smf.ols(\"earn_78 ~ treated +\" + \" + \".join(covar_list), data=df).fit()\n",
    "    # lin_reg = sm.OLS(out, covars).fit()\n",
    "    return lin_reg.params['treated'], lin_reg.bse['treated'], lin_reg.pvalues['treated'], lin_reg\n",
    "\n",
    "results = {}\n",
    "for strata in range(1, 6):\n",
    "    df_stat = df[df['stratum'] == strata].drop(columns=['propensity_score', 'stratum','weight', 'weight_log'])\n",
    "    effect, se, p_value, model = lin_model(df_stat)\n",
    "    results[strata]= {\n",
    "            'effect': effect,\n",
    "            'se': se,\n",
    "            'p_value': p_value,\n",
    "            'n_treated': sum(stratum_data['treated'] == 1),\n",
    "            'n_control': sum(stratum_data['treated'] == 0),\n",
    "            'model': model\n",
    "        }\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.8445073423172282)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate overall weighted average effect\n",
    "total_treated = sum(res['n_treated'] for res in results.values())\n",
    "weighted_effect = sum(res['effect'] * res['n_treated'] for res in results.values()) / total_treated\n",
    "weighted_effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. ATT using within strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strata_att(df):\n",
    "    strata_effect = {}\n",
    "    strata_weight = {}\n",
    "\n",
    "    for strata in range(1, 6):\n",
    "        df_stat = df[df['stratum'] == strata].drop(columns=['propensity_score', 'stratum','weight', 'weight_log'])\n",
    "        effect = results[strata]['effect']\n",
    "        n_treated = results[strata]['n_treated']\n",
    "        \n",
    "        strata_effect[strata] = effect\n",
    "        strata_weight[strata] = n_treated\n",
    "    total_weight = sum(strata_weight.values())\n",
    "    weighted_effect = sum(strata_effect[s] * strata_weight[s] for s in range(1, 6)) / total_weight\n",
    "\n",
    "    return weighted_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.8445073423172282)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_strata = strata_att(df)\n",
    "att_strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE= 4.440892098500626e-16\n"
     ]
    }
   ],
   "source": [
    "att_boots = []\n",
    "for _ in range(1000):\n",
    "    boot_sample = resample(df)\n",
    "    att_boots.append(strata_att(boot_sample))\n",
    "\n",
    "att_std_error = np.std(att_boots)\n",
    "print(\"SE=\", att_std_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error of the strata estimates is smaller than for the strictly weighted estimates. This is expected because by construction, although total N in the regression is less, the control group more closely resembles the treated group. This makes the variance of observables and outcomes smaller, leading to smaller SE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Are these estimates reasonable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These estimates both assume unconfoundedness, which may or may not be valid depending on whether you believe an argument about treatment being a related to the distrobutions of previous earnings or actions. Also, although the SE is smaller and the estimate is more precise for the stratified regression, this regression loses some of the nuance of the relationships of differences between groups as opposed to the more strictly defined differences within groups. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
